{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_fill_trajectories(pandas_data_frames, default_value=None):\n",
    "    # merge all trajectories keeping all time steps\n",
    "    df = pd.DataFrame().join(pandas_data_frames, how='outer')\n",
    "\n",
    "    # forward fill to make it a propper step function\n",
    "    df = df.fillna(method='ffill')\n",
    "    if default_value is None:\n",
    "        # backward fill to replace the NaNs for the early times by the\n",
    "        # performance of a random configuration\n",
    "        df = df.fillna(method='bfill')\n",
    "    else:\n",
    "        df = df.fillna(default_value)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_trajectories(losses, iterations):\n",
    "    dfs = []\n",
    "    for i in range(len(losses)):\n",
    "        loss = losses[i]\n",
    "        iteration = iterations[i]\n",
    "        # print('Run %d, Min: %f'%(i, loss))\n",
    "        df = pd.DataFrame({str(i): loss}, index=iteration)\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = merge_and_fill_trajectories(dfs, default_value=None)\n",
    "    if df.empty:\n",
    "        pass\n",
    "\n",
    "    return np.array(df.T), np.array(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(predictor, path, epochs, metric='valid_acc', dataset='cifar10', ug=False):\n",
    "    \n",
    "    output = []\n",
    "    time = []\n",
    "    nan_count = 0\n",
    "    missing_results_count = 0\n",
    "    \n",
    "    algo_path = os.path.join(path, predictor)\n",
    "    for seed_dir in os.listdir(algo_path):\n",
    "        result_file = os.path.join(algo_path, seed_dir, 'errors.json')\n",
    "        result = json.load(open(result_file))\n",
    "        \n",
    "        config = result[0]\n",
    "        val_acc = result[1]['valid_acc'][:epochs]\n",
    "        surr_time = np.array(result[1]['runtime'])[:epochs]\n",
    "        if ug:\n",
    "            runtime = 200*np.array(result[1]['train_time'])[:epochs] + surr_time\n",
    "        else:\n",
    "            runtime = np.array(result[1]['train_time'])[:epochs] + surr_time\n",
    "\n",
    "        val_err = [100 - x for x in val_acc]\n",
    "        val_incumbent = [min(val_err[:epoch]) for epoch in range(1, len(val_err)+1)]\n",
    "        runtime = [sum(runtime[:epoch]) for epoch in range(1, len(runtime)+1)]\n",
    "\n",
    "        if metric == 'valid_acc':\n",
    "            incumbent = val_incumbent\n",
    "        elif metric == 'test_acc':\n",
    "            test_err = [100 - x for x in result[1]['test_acc']]\n",
    "            inc_idx, best, best_idx = [], np.inf, 0\n",
    "            for i, err in enumerate(val_err):\n",
    "                if err < best:\n",
    "                    best, best_idx = err, i\n",
    "                inc_idx.append(best_idx)\n",
    "            incumbent = [test_err[idx] for idx in inc_idx]\n",
    "\n",
    "        if len(incumbent) == epochs:\n",
    "            output.append(incumbent)\n",
    "            time.append(runtime)\n",
    "        else:\n",
    "            nan_count += 1\n",
    "\n",
    "    output = np.array(output)\n",
    "    time = np.array(time)\n",
    "\n",
    "    output, time = get_trajectories(output, time)\n",
    "    \n",
    "    print(predictor, 'output shape', output.shape, 'nans', nan_count, 'missing files', missing_results_count)\n",
    "    mean = np.mean(output, axis=0)\n",
    "    std = np.std(output, axis=0)\n",
    "    std_error = np.sqrt(np.var(output, axis=0, ddof=1)/np.asarray(output).shape[0])\n",
    "    return mean, std, std_error, time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up colors and plot markings\n",
    "defaults = [(0.12156862745098039, 0.4666666666666667, 0.7058823529411765),\n",
    "            (1.0, 0.4980392156862745, 0.054901960784313725),\n",
    "            (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "            (0.8392156862745098, 0.15294117647058825, 0.1568627450980392),\n",
    "            (0.5803921568627451, 0.403921568627451, 0.7411764705882353),\n",
    "            (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),\n",
    "            (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),\n",
    "            (0.4980392156862745, 0.4980392156862745, 0.4980392156862745),\n",
    "            (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),\n",
    "            (0.09019607843137255, 0.7450980392156863, 0.8117647058823529)]\n",
    "\n",
    "# goes up to 24\n",
    "c_max = 9\n",
    "colors = [*defaults[:c_max], *defaults[:c_max], *defaults[:c_max]]\n",
    "fmts = [*['-']*c_max, *['--']*c_max, *[':']*c_max]\n",
    "markers = [*['^']*c_max, *['v']*c_max, *['o']*c_max]\n",
    "\n",
    "# https://matplotlib.org/2.1.2/api/_as_gen/matplotlib.pyplot.plot.html\n",
    "\n",
    "\n",
    "pred_label_dict={\n",
    "    'valloss':'Val. Loss', 'valacc':'Val. Acc.', 'sotl':'SoTL', 'bananas':'BANANAS',\n",
    "    'mlp':'Feedforward', 'gbdt':'GBDT', 'gcn':'GCN', 'bonas_gcn':'BONAS', 'xgb':'XGB',\n",
    "    'ngb':'NGB', 'rf':'RF', 'jacov':'Jacob. Cov.', 'dngo':'DNGO', 'bohamiann':'BOHAMIANN', \n",
    "    'bayes_lin_reg':'Bayes. Lin. Reg.', 'ff_keras':'FF-Keras', 'gp':'GP', 'sparse_gp':'Sparse GP', \n",
    "    'var_sparse_gp':'Var. Sparse GP', 'seminas':'SemiNAS', 'lcsvr':'LcSVR', 'snip':'SNIP', 'sotle':'SoTLE',\n",
    "    'bonas':'BONAS', 'omni_lofi':'Omni Lofi', 'nao': 'NAO', 'lgb': 'LGB'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters for the experiments\n",
    "epochs = 300\n",
    "results_dict = {}\n",
    "\n",
    "folder = os.path.expanduser('re_pred_run_0/cifar10/nas_predictors/nasbench201')\n",
    "predictors=('mlp', 'lgb', 'xgb', 'rf', 'bayes_lin_reg', 'gp')\n",
    "\n",
    "for i, predictor in enumerate(predictors):\n",
    "    mean, std, std_error, runtime = get_results(predictor, folder, epochs=epochs, metric='test_acc', ug=True)\n",
    "    results_dict[predictor] = {'label':pred_label_dict[predictor], \n",
    "                               'key':predictor, 'mean':mean, 'std':std, \n",
    "                               'std_error': std_error, 'runtime': runtime}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# plot performance vs runtime\n",
    "\n",
    "# didn't run them long enough to do logspace here. (These experiments took surprisingly long to run)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.linestyle'] = 'dotted'\n",
    "\n",
    "plot_zoomed = False\n",
    "plot_sem = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[8, 4])\n",
    "if plot_zoomed:\n",
    "    sub_axes = plt.axes([.6, .6, .25, .25]) \n",
    "\n",
    "for i, key in enumerate(predictors):\n",
    "    mean = results_dict[key]['mean']\n",
    "    sem = results_dict[key]['std_error']\n",
    "    label = results_dict[key]['label']\n",
    "    x = results_dict[key]['runtime']\n",
    "    \n",
    "    ax.plot(x, mean, label=label, color=colors[i], linestyle=fmts[i])\n",
    "    if plot_sem:\n",
    "        ax.fill_between(x, mean-1*sem, mean+1*sem,\n",
    "                        color=colors[i], alpha=0.2)\n",
    "    \n",
    "    if plot_zoomed:\n",
    "        X_detail = x[-10000:]\n",
    "        Y_detail = mean[-10000:]\n",
    "        sem_detail = sem[-10000:]\n",
    "        sub_axes.plot(X_detail, Y_detail, color=colors[i], linestyle=fmts[i])\n",
    "        sub_axes.fill_between(X_detail, Y_detail-1*sem_detail, Y_detail+1*sem_detail,\n",
    "                         color=colors[i], alpha=0.2)\n",
    "        sub_axes.tick_params(labelbottom=False) \n",
    "        sub_axes.set_xlim([700000, 900000])\n",
    "    \n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim([7, 11])\n",
    "ax.set_xlim([1e4, 1.6e6])\n",
    "\n",
    "ax.legend(loc=(1.04,0))\n",
    "ax.set_xlabel('Runtime [s] (simulated)')\n",
    "ax.set_ylabel('Test error (%)')\n",
    "ax.grid(True, which=\"both\",ls=\"-\", alpha=.5)\n",
    "ax.set_title('Test error vs. train time for the Predictor Framework on NAS-Bench-201')\n",
    "plt.savefig('plot_nb201.pdf', bbox_inches = 'tight', pad_inches = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
